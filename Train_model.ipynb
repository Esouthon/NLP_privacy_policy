{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fddb97",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed29575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn \n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from transformers import TFBertModel, BertConfig, BertTokenizerFast\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "import keras\n",
    "import torch.nn.functional as Fun\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5df7390",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934c0bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(1) a Federal, State, or local law enforcement...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>(1) a Federal, State, or local law enforcement...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>(1) announcing the change on the home page of ...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>(1) comply with the law or legal processes;</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>(1) comply with the law or with legal process;</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  value\n",
       "0           0  (1) a Federal, State, or local law enforcement...    2.0\n",
       "1           1  (1) a Federal, State, or local law enforcement...    2.0\n",
       "2           2  (1) announcing the change on the home page of ...    7.0\n",
       "3           3        (1) comply with the law or legal processes;    2.0\n",
       "4           4     (1) comply with the law or with legal process;    2.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data\n",
    "#Change the path to read data\n",
    "#The data must be in 1 Csv File with text and value column\n",
    "path_data='/flush5/sou090/model/Train_data/data.csv'\n",
    "df=pd.read_csv(path_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e902e5",
   "metadata": {},
   "source": [
    "### 1. Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e930c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b86c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29740"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one=OneHotEncoder(sparse=False)\n",
    "encoded=one.fit_transform(df[['value']])\n",
    "len(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793aff9d",
   "metadata": {},
   "source": [
    "### 2. Creat new data with the encoded value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4d1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29740/29740 [01:32<00:00, 321.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1) a Federal, State, or local law enforcement...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1) a Federal, State, or local law enforcement...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1) announcing the change on the home page of ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1) comply with the law or legal processes;</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1) comply with the law or with legal process;</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(1) following the \\</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(1) identify the terms of any special offers y...</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(1) identify the terms of any special offers y...</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1) information we receive from you</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1) personal information,</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  (1) a Federal, State, or local law enforcement...   \n",
       "1  (1) a Federal, State, or local law enforcement...   \n",
       "2  (1) announcing the change on the home page of ...   \n",
       "3        (1) comply with the law or legal processes;   \n",
       "4     (1) comply with the law or with legal process;   \n",
       "5                                (1) following the \\   \n",
       "6  (1) identify the terms of any special offers y...   \n",
       "7  (1) identify the terms of any special offers y...   \n",
       "8                (1) information we receive from you   \n",
       "9                          (1) personal information,   \n",
       "\n",
       "                                               value  \n",
       "0  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "1  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "4  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "5  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "6  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "7  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "8  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  \n",
       "9  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = {'text' : [], 'value' : []}\n",
    "df_model = pd.DataFrame(head,dtype=object)\n",
    "for k in tqdm(range (len(df))):\n",
    "    df_model.loc[k]=[df['text'][k],encoded[k]]\n",
    "df_model.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9727143",
   "metadata": {},
   "source": [
    "### 3. Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f7827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26766 2974\n"
     ]
    }
   ],
   "source": [
    "#Split data\n",
    "train_df, test_df = train_test_split(df_model,test_size=0.1)\n",
    "print(len(train_df),len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef371a0",
   "metadata": {},
   "source": [
    "### Check the len max "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f849030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length of text:  247 words\n"
     ]
    }
   ],
   "source": [
    "ex_len = []\n",
    "for i in train_df['text']:\n",
    "  ex_len.append(len(i.split()))\n",
    "print('max length of text: ', max(ex_len), 'words')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92784a0",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dcd68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizerFast.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce1cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder the function to tokenize the data\n",
    "def encoder(df, tokenizer, label = 'text', maxLen = 254):\n",
    "    input_id = []\n",
    "    token_type = []\n",
    "    attention_mask = []\n",
    "    for i in df[label].values:\n",
    "        token = tokenizer(i, max_length = maxLen, truncation = True, padding = 'max_length', add_special_tokens = True)\n",
    "        input_id.append(token['input_ids'])\n",
    "        token_type.append(token['token_type_ids'])\n",
    "        attention_mask.append(token['attention_mask'])\n",
    "    return np.array(input_id), np.array(token_type), np.array(attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2204224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function to tokenize data\n",
    "train_d = encoder(train_df, tokenizer)\n",
    "test_d = encoder(test_df, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c502297",
   "metadata": {},
   "source": [
    "## Config Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f004b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = BertConfig.from_pretrained(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2ab7d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.22.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config.output_hidden_states = True\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b691c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert = TFBertModel.from_pretrained(bert_model, config = model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6777f5e3",
   "metadata": {},
   "source": [
    "### 1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c4d900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tunable parameters\n",
    "max_len = 254\n",
    "#fix learning_rate\n",
    "learning_rate = 1e-4\n",
    "epochs = 3\n",
    "\n",
    "#callbacks\n",
    "#Change the path_checkpoint\n",
    "ckpt_dir = '/flush5/sou090/model/save/ckpt{epoch:02d}.h5'\n",
    "ckpt = ModelCheckpoint(\n",
    "    filepath = ckpt_dir,\n",
    "    save_freq = 'epoch',\n",
    "    save_weights_only=True)\n",
    "callbacks = [ckpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b994399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = Adam(learning_rate = learning_rate)\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "#Loss\n",
    "loss = 'categorical_crossentropy'\n",
    "#Metrics\n",
    "metrics=tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\", dtype=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e768b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_i = Input(shape = (max_len, ), dtype = tf.int32, name = 'input_ids')\n",
    "token_type_ids_i = Input(shape = (max_len, ), dtype = tf.int32, name = 'token_type_ids')\n",
    "attention_mask_i = Input(shape = (max_len, ), dtype = tf.int32, name = 'attention_mask')\n",
    "inputs = [input_ids_i, token_type_ids_i, attention_mask_i]\n",
    "\n",
    "bert_output = bert(input_ids_i, token_type_ids = token_type_ids_i, attention_mask = attention_mask_i)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b911c9f1",
   "metadata": {},
   "source": [
    "### 2. Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0867c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 254)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 254)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, 254)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]',         \n",
      "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
      "                                n_state=(None, 254,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=(                                               \n",
      "                                (None, 254, 768),                                                 \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768)),                                               \n",
      "                                 attentions=None, c                                               \n",
      "                                ross_attentions=Non                                               \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[1][13]']         \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           38450       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25)           1275        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           260         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           110         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,522,335\n",
      "Trainable params: 109,522,335\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_output = bert(input_ids_i, token_type_ids = token_type_ids_i, attention_mask = attention_mask_i)[0]\n",
    "output = bert_output[:, 0, :]\n",
    "\n",
    "output = Dropout(0.15)(output)\n",
    "\n",
    "output =Dense(50,activation='relu')(output)\n",
    "output=Dense(25,activation='relu')(output)\n",
    "output=Dense(10,activation='relu')(output)\n",
    "output = Dense(10, activation = 'softmax')(output) #Adding a softmax layer for softmax regression with categorical \n",
    "#cross entropy\n",
    "\n",
    "model = Model(inputs = inputs, outputs = output)\n",
    "\n",
    "model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "100496c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 254)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 254)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, 254)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]',         \n",
      "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
      "                                n_state=(None, 254,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=(                                               \n",
      "                                (None, 254, 768),                                                 \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768),                                                \n",
      "                                 (None, 254, 768)),                                               \n",
      "                                 attentions=None, c                                               \n",
      "                                ross_attentions=Non                                               \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 768)         0           ['tf_bert_model[1][13]']         \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 768)          0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           38450       ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 25)           1275        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           260         ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           110         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,522,335\n",
      "Trainable params: 40,095\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[3].trainable = False # Trying to make the bert layers non-trainable\n",
    "model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e5a62b",
   "metadata": {},
   "source": [
    "### 3. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f32dbe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datas\n",
    "train_l = train_df['value'].values\n",
    "\n",
    "val_prob = 0.1\n",
    "split = int(len(train_l)*(1 - val_prob))\n",
    "\n",
    "train_x = tuple(np.array(train_d)[:, :split, :])\n",
    "train_y =np.array(train_l)[:split]\n",
    "\n",
    "val_x = tuple(np.array(train_d)[:, split:, :])\n",
    "val_y =np.array(train_l)[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "130f638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yl = []\n",
    "val_yl = []\n",
    "for i in range(0,train_y.shape[0]):\n",
    "    train_yl.append(list(train_y[i]))\n",
    "for i in range(0,val_y.shape[0]):\n",
    "    val_yl.append(list(val_y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5ee2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_yll = np.asarray(train_yl).astype(np.float32)\n",
    "val_yl1 = np.asarray(val_yl).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cb8312",
   "metadata": {},
   "source": [
    "## Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efb62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_x, train_yll, validation_data = (val_x, val_yl1), epochs = 50,callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955d9e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the path to save the model\n",
    "model.save('/flush5/sou090/model/save/model_project.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730bb67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save= loaded_model = tf.keras.models.load_model('/flush5/sou090/model/save/model_project.h5', custom_objects={\"TFBertModel\": TFBertModel})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c1559",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#print(model_save.history.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f063fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('accuracy.pdf')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.savefig('loss.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601350c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
